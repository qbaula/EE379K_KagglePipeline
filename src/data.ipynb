{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data (filename, \n",
    "               fill=False, fill_type='mean',\n",
    "               scale=False, log=False):\n",
    "    \n",
    "    data = pd.read_csv('../data/base/' + filename, index_col=0)\n",
    "\n",
    "    if fill:\n",
    "        data['F5'] = data['F5'].fillna(11.0)\n",
    "        data['F19'] = data['F19'].fillna(data['F19'].mean())\n",
    "    \n",
    "    if scale:\n",
    "        numer_cols = []\n",
    "        for c in data:\n",
    "            if c != 'Y':\n",
    "                data[c] = StandardScaler().fit_transform(data[c].values.reshape(-1,1))\n",
    "    \n",
    "    if log:\n",
    "        for c in data:\n",
    "            if c != 'Y':\n",
    "                data[c] = np.log(data[c]+1)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def save_data (filename, save_data):\n",
    "    #submission = pd.DataFrame(columns=['Y'], index=index_data.index, data=predictions)\n",
    "    save_data.to_csv('../data/processed/' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49998, 28)\n",
      "(50000, 27)\n"
     ]
    }
   ],
   "source": [
    "train = load_data ('train.csv', fill=True)\n",
    "test = load_data ('test.csv', fill=True)\n",
    "print (train.shape)\n",
    "print (test.shape)\n",
    "\n",
    "y_train = train['Y']\n",
    "X_train = train.drop (['Y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data('train_fill.csv', train)\n",
    "save_data('test_fill.csv', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data not filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49998, 28)\n",
      "(50000, 27)\n"
     ]
    }
   ],
   "source": [
    "train_missing = load_data ('train.csv', fill=False)\n",
    "test_missing = load_data ('test.csv', fill=False)\n",
    "print (train_missing.shape)\n",
    "print (test_missing.shape)\n",
    "\n",
    "save_data('train_missing.csv', train_missing)\n",
    "save_data('test_missing.csv', test_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data with interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49998, 34)\n",
      "(50000, 33)\n"
     ]
    }
   ],
   "source": [
    "train_inter = load_data ('train.csv', fill=True)\n",
    "test_inter = load_data ('test.csv', fill=True)\n",
    "                \n",
    "terms = train_inter[['F23', 'F14']]\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False)\n",
    "inter_terms = poly.fit_transform(terms)[:,1:]\n",
    "inter_terms = pd.DataFrame(inter_terms)\n",
    "inter_terms = inter_terms.rename(lambda x: x+1)\n",
    "train_inter = pd.concat([train_inter, inter_terms, train_inter['F23']**2], axis=1)\n",
    "\n",
    "terms = test_inter[['F23', 'F14']]\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False)\n",
    "inter_terms = poly.fit_transform(terms)[:,1:]\n",
    "inter_terms = pd.DataFrame(inter_terms)\n",
    "inter_terms = inter_terms.rename(lambda x: x+49999)\n",
    "test_inter = pd.concat([test_inter, inter_terms, test_inter['F23']**2], axis=1)\n",
    "                         \n",
    "print (train_inter.shape)\n",
    "print (test_inter.shape)\n",
    "\n",
    "y_train_inter = train_inter['Y']\n",
    "X_train_inter = train_inter.drop (['Y'], axis=1)\n",
    "\n",
    "save_data('train_inter.csv', train_inter)\n",
    "save_data('test_inter.csv', test_inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kian/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49998, 28)\n",
      "(50000, 27)\n"
     ]
    }
   ],
   "source": [
    "train_scaled = load_data ('train.csv', fill=True, scale=True)\n",
    "test_scaled = load_data ('test.csv', fill=True, scale=True)\n",
    "print (train_scaled.shape)\n",
    "print (test_scaled.shape)\n",
    "\n",
    "y_train_scaled = train_scaled['Y']\n",
    "X_train_scaled = train_scaled.drop (['Y'], axis=1)\n",
    "\n",
    "save_data('train_scaled.csv', train_scaled)\n",
    "save_data('test_scaled.csv', test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data log(x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49998, 28)\n",
      "(50000, 27)\n"
     ]
    }
   ],
   "source": [
    "train_log = load_data ('train.csv', fill=True, log=True)\n",
    "test_log = load_data ('test.csv', fill=True, log=True)\n",
    "print (train_log.shape)\n",
    "print (test_log.shape)\n",
    "\n",
    "y_train_log = train_log['Y']\n",
    "X_train_log = train_log.drop (['Y'], axis=1)\n",
    "\n",
    "save_data('train_log.csv', train_log)\n",
    "save_data('test_log.csv', test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values per column:\n",
      "F1         9\n",
      "F2        12\n",
      "F3     49998\n",
      "F4         9\n",
      "F5        12\n",
      "F6      1880\n",
      "F7         9\n",
      "F8         9\n",
      "F9       322\n",
      "F10       23\n",
      "F11       43\n",
      "F12        9\n",
      "F13       10\n",
      "F14       16\n",
      "F15       10\n",
      "F16      310\n",
      "F17        9\n",
      "F18       83\n",
      "F19     8771\n",
      "F20       10\n",
      "F21      334\n",
      "F22       55\n",
      "F23    42562\n",
      "F24        9\n",
      "F25       14\n",
      "F26       83\n",
      "F27    41705\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (\"Unique values per column:\")\n",
    "print (X_train.apply(lambda x: len(x.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [1, 2, 3, 4, 5, 6, 8, 12, 18]\n",
      "F1: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12]\n",
      "F2: [0, 1, 2, 3, 4, 5, 6, 7, 9, 11, 96, 98]\n",
      "F2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 96, 98]\n",
      "F4: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "F4: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 17]\n",
      "F5: [0.0, 1.0, 2.0, 3.0, 5.0, nan, 4.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "F5: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, nan, 7.0, 8.0, 10.0, 20.0]\n",
      "F7: [1, 2, 3, 4, 5, 6, 8, 10, 23]\n",
      "F7: [1, 2, 3, 4, 5, 6, 7, 8, 10, 14, 18]\n",
      "F8: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "F8: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13]\n",
      "F10: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 29, 54]\n",
      "F10: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 23, 25, 26]\n",
      "F12: [1, 2, 3, 4, 5, 6, 7, 11, 12]\n",
      "F12: [1, 2, 3, 4, 5, 6, 7, 8, 9, 17]\n",
      "F13: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "F13: [1, 2, 3, 4, 5, 7, 8, 9]\n",
      "F14: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 96, 98]\n",
      "F14: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 96, 98]\n",
      "F15: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "F15: [1, 2, 3, 4, 5, 6, 7, 10]\n",
      "F17: [1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "F17: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "F20: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "F20: [1, 2, 3, 4, 5, 6, 7, 8, 13, 15]\n",
      "F24: [1, 2, 3, 4, 5, 6, 7, 8, 10]\n",
      "F24: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "F25: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 96, 98]\n",
      "F25: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 96, 98]\n",
      "15: ['F1', 'F2', 'F4', 'F5', 'F7', 'F8', 'F10', 'F12', 'F13', 'F14', 'F15', 'F17', 'F20', 'F24', 'F25']\n"
     ]
    }
   ],
   "source": [
    "categ_cols = []\n",
    "for c in X_train:\n",
    "    if len(X_train[c].unique()) <= 30:\n",
    "        print (str(c) + ': ' + str(sorted(train[c].unique())))\n",
    "        print (str(c) + ': ' + str(sorted(test[c].unique())))\n",
    "        categ_cols.append(c)\n",
    "\n",
    "print (str(len(categ_cols)) + ': ' + str(categ_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F3 (49998 unique values) : -0.372758387 - 29110.04058\n",
      " F3 (49998 unique values) : -0.364406804 - 50708.04549\n",
      " F6 (1880  unique values) : 1 - 8194101904\n",
      " F6 (1880  unique values) : 1 - 69627726\n",
      " F9 (322   unique values) : 1 - 59249\n",
      " F9 (312   unique values) : 1 - 45887\n",
      "F11 (43    unique values) : 18 - 63\n",
      "F11 (42    unique values) : 19 - 60\n",
      "F16 (310   unique values) : 1.77 - 35807.1\n",
      "F16 (307   unique values) : 1.77 - 115009.29\n",
      "F18 (83    unique values) : 98 - 184\n",
      "F18 (83    unique values) : 77 - 182\n",
      "F19 (8771  unique values) : 0.0 - 3008750.0\n",
      "F19 (8802  unique values) : 0.0 - 702500.0\n",
      "F21 (334   unique values) : 0 - 630367\n",
      "F21 (295   unique values) : 0 - 41061\n",
      "F22 (55    unique values) : 0 - 58\n",
      "F22 (50    unique values) : 0 - 54\n",
      "F23 (42562 unique values) : 0.0 - 29110.0\n",
      "F23 (42460 unique values) : 0.0 - 50708.0\n",
      "F26 (83    unique values) : 21 - 107\n",
      "F26 (83    unique values) : 0 - 105\n",
      "F27 (41705 unique values) : 0.0 - 329664.0\n",
      "F27 (41563 unique values) : 0.0 - 326442.0\n",
      "12: ['F3', 'F6', 'F9', 'F11', 'F16', 'F18', 'F19', 'F21', 'F22', 'F23', 'F26', 'F27']\n"
     ]
    }
   ],
   "source": [
    "numer_cols = []\n",
    "for c in X_train:\n",
    "    if len(X_train[c].unique()) > 30:\n",
    "        print ('%3s'%(c) + ' (' + '%-5d'%(len(train[c].unique())) + ' unique values) : ' + str(min(train[c])) + ' - ' + str(max(train[c])))\n",
    "        print ('%3s'%(c) + ' (' + '%-5d'%(len(test[c].unique())) + ' unique values) : ' + str(min(test[c])) + ' - ' + str(max(test[c])))\n",
    "\n",
    "        numer_cols.append(c)\n",
    "\n",
    "print (str(len(numer_cols)) + ': ' + str(numer_cols))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
